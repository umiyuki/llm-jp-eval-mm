[project]
name = "eval-mm"
description = "eval-mm is a tool for evaluating Multi-Modal Large Language Models."
authors = [
    { name = "Silviase", email = "koki.maeda@nlp.c.titech.ac.jp" },
    { name = "speed1313", email = "sugiura.issa.q29@kyoto-u.jp" },
]
dependencies = [
    "datasets==2.18.0",
    "requests>=2.32.3",
    "python-dotenv>=1.0.1",
    "openai>=1.42.0",
    "rouge-score>=0.1.2",
    "emoji>=2.12.1",
    "fugashi>=1.3.2",
    "unidic-lite>=1.0.8",
    "sacrebleu[ja]>=2.4.3",
    "pdf2image>=1.17.0",
    "protobuf>=5.29.1",
    "backoff>=2.2.1",
    "scipy>=1.15.1",
    "torch>=2.5.1",
    "webdataset>=0.2.111",
    "av>=14.1.0",
    "loguru>=0.7.3",
    "litellm>=1.0.0",  # LiteLLMを追加
    "google-generativeai>=0.7.0",  # Google Gemini用
]
readme = "README.md"
license = "Apache-2.0"
requires-python = ">= 3.12.1"

dynamic = [
    "version"
]

[project.urls]
Repository = "https://github.com/llm-jp/llm-jp-eval-mm"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.version]
path = "src/eval_mm/_version.py"

[tool.hatch.build]
exclude = [
    "result",
    "scripts",
]

[tool.uv.sources]
mantis-vl = { git = "https://github.com/TIGER-AI-Lab/Mantis" }
s2wrapper = { git = "https://github.com/bfshi/scaling_on_scales.git" }
# You need to comment out the following line when you use gemmm3
# transformers = { git = "https://github.com/huggingface/transformers", rev = "v4.49.0-Gemma-3" }

[tool.hatch.metadata]
allow-direct-references = true

[dependency-groups]
dev = [
    "mypy>=1.15.0",
    "pytest>=8.3.4",
    "seaborn>=0.13.2",
]

evovlm = [
    "flash-attn>=2.7.3",
    "transformers==4.42.4",
    "mantis-vl",
]
vilaja = [
    "flash-attn>=2.7.3",
    "accelerate==0.27.2",
    "deepspeed>=0.16.3",
    "einops>=0.8.0",
    "psutils>=3.3.9",
    "s2wrapper",
    "sentencepiece>=0.2.0",
    "torchvision>=0.20.1",
    "transformers==4.37.2",
]
sarashina = [
    "accelerate>=0.27.2",
    "pillow>=10.4.0",
    "protobuf>=5.29.3",
    "sentencepiece>=0.2.0",
    "torch>=2.5.1",
    "torchvision>=0.20.1",
    "transformers==4.47.0",
]
gemma = [
    "flash-attn>=2.7.3",
    "accelerate>=0.27.2",
    "timm==1.0.13",
    "transformers",
]
normal = [
    "flash-attn>=2.7.3",
    "accelerate>=1.2.1",
    "qwen-vl-utils>=0.0.8",
    "sentencepiece>=0.2.0",
    "timm>=1.0.13",
    "torchvision>=0.20.1",
    "transformers>=4.49.0",
]
pixtral = [
    "flash-attn>=2.7.3",
    "mistral-common==1.5.0",
    "vllm==0.6.5",
]


[tool.uv]
conflicts = [
    [
      { group = "evovlm" },
      { group = "vilaja" },
      { group = "normal" },
      { group = "pixtral" },
      { group = "gemma" },
      { group = "sarashina"},
    ],
]
no-build-isolation-package = ["flash-attn"]

[tool.hatch.build.targets.wheel]
packages = ["src/eval_mm"]
