import requests
from PIL import Image
from vllm import LLM
from vllm.sampling_params import SamplingParams
from typing import Union
import base64
from io import BytesIO


def image_to_base64(img):
    buffer = BytesIO()
    # Check if the image has an alpha channel (RGBA)
    if img.mode == "RGBA":
        # Convert the image to RGB mode
        img = img.convert("RGB")
    img.save(buffer, format="JPEG")
    buffer.seek(0)
    img_str = base64.b64encode(buffer.getvalue()).decode("ascii")
    return img_str


def image_to_content(image: Image.Image) -> dict:
    base64_image = image_to_base64(image)
    content = {
        "type": "image_url",
        "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"},
    }
    return content


class VLM:
    model_id = "mistralai/Pixtral-12B-2409"

    def __init__(self) -> None:
        self.model = LLM(
            model=self.model_id,
            tokenizer_mode="mistral",
            tensor_parallel_size=2,
        )

    def generate(
        self,
        images: Union[Image.Image, list[Image.Image]],
        text: str,
        max_new_tokens: int = 256,
    ):
        if isinstance(images, list):
            content = [image_to_content(image) for image in images]
        else:
            content = [image_to_content(images)]

        content.extend([{"type": "text", "text": text}])
        messages = [
            {
                "role": "user",
                "content": content,
            }
        ]

        sampling_params = SamplingParams(max_tokens=max_new_tokens)
        outputs = self.model.chat(
            messages,
            sampling_params=sampling_params,
        )
        return outputs[0].outputs[0].text


if __name__ == "__main__":
    model = VLM()
    image_file = "http://images.cocodataset.org/val2017/000000039769.jpg"
    image = Image.open(requests.get(image_file, stream=True).raw)
    print(model.generate(image, "What is in the image?"))

    # Not Supported Multi-Image Inference
    # multi_images = [image for _ in range(3)]
    # print(model.generate(multi_images, "What is the difference between these images?"))
